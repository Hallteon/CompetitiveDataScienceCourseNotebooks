{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747cdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d64cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 1501 entries, 0 to class\n",
      "dtypes: float64(1500), int64(1)\n",
      "memory usage: 11.5 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "data = pd.read_csv('../data/data_real_train.csv', sep=';')\n",
    "\n",
    "categorical_features = []\n",
    "\n",
    "for cat in categorical_features:\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    data[cat] = lbl.fit_transform(data[cat].astype(str))\n",
    "    data[cat] = data[cat].astype('category')\n",
    "    \n",
    "data.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dccbdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.unique(data['class'])\n",
    "data['class'] = data['class'].replace(class_names, np.arange(data['class'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37820b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2drop = ['class']\n",
    "categorical_features = []\n",
    "numerical_features = [c for c in data.columns if c not in categorical_features and c not in cols2drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3235b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data.drop(cols2drop, axis=1), \n",
    "                                                    data['class'],\n",
    "                                                    test_size=.25,\n",
    "                                                    stratify=data['class'],\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f292990",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cat = {\n",
    "             'n_estimators' : 200,\n",
    "              # 'learning_rate': .03,\n",
    "              'depth' : 3,\n",
    "              'verbose': False,\n",
    "              'use_best_model': True,\n",
    "              'cat_features' : categorical_features,\n",
    "              'text_features': [],\n",
    "              # 'train_dir' : '/home/jovyan/work/catboost',\n",
    "              'border_count' : 64,\n",
    "              'l2_leaf_reg' : 1,\n",
    "              'bagging_temperature' : 2,\n",
    "              'rsm' : 0.51,\n",
    "              'loss_function': 'MultiClass',\n",
    "              'auto_class_weights' : 'Balanced', #try not balanced\n",
    "              'random_state': 42,\n",
    "              'use_best_model': False,\n",
    "              # 'custom_metric' : ['AUC', 'MAP'] # Не работает внутри sklearn.Pipelines\n",
    "         }\n",
    "\n",
    "cat_model = cb.CatBoostClassifier(**params_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f5d8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_index = [i for i in range(data.shape[1]) if data.columns[i] in categorical_features]\n",
    "params_lgbm = {\n",
    "    \"num_leaves\": 200,\n",
    "    \"n_estimators\": 200,\n",
    "    # \"max_depth\": 7,\n",
    "    \"min_child_samples\": None,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"min_data_in_leaf\": 5,\n",
    "    \"feature_fraction\": 0.98,\n",
    "    # \"categorical_feature\": cat_cols,\n",
    "    'reg_alpha' : 3.0,\n",
    "    'reg_lambda' : 5.0,\n",
    "    'categorical_feature': categorical_features_index\n",
    "}\n",
    "\n",
    "lgbm_model = lgbm.LGBMClassifier(**params_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdc1ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    \"eta\": 0.05,\n",
    "    'n_estimators' : 200,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    # \"colsample_bytree\": 0.95,\n",
    "    'min_child_weight' : 0.1,\n",
    "    'gamma': .01,\n",
    "    'reg_lambda' : 0.1,\n",
    "    'reg_alpha' : 0.5,\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"eval_metric\": \"mae\",\n",
    "    'tree_method' : 'hist', # Supported tree methods for cat fs are `gpu_hist`, `approx`, and `hist`.\n",
    "    'enable_categorical' : True\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4441c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80025560",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e941dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"numerical\", numerical_transformer, numerical_features),\n",
    "    (\"categorical\", categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e650b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    \n",
    "    \n",
    "    (\"ExtraTrees\",  make_pipeline(preprocessor, ExtraTreesClassifier(n_estimators = 400, max_depth = 6, min_samples_leaf = 2, \n",
    "                                                              bootstrap = True, class_weight = 'balanced', # ccp_alpha = 0.001, \n",
    "                                                              random_state = 75, verbose=False, n_jobs=-1,))),\n",
    "    \n",
    "\n",
    "    (\"XGBoost\", xgb_model),\n",
    "#     (\"LightGBM\", lgbm_model),\n",
    "    (\"CatBoost\", cat_model),\n",
    "    \n",
    "    # То, что не дало прироста в ансамбле\n",
    "    # (\"SVM\", make_pipeline(preprocessor, LinearSVC(verbose=False))),\n",
    "    # (\"MLP\", make_pipeline(preprocessor, MLPClassifier(verbose=False, hidden_layer_sizes=(100, 30, ), alpha=0.001,random_state=75, max_iter = 1300, ))),\n",
    "#     (\"Random_forest\",  make_pipeline(preprocessor, RandomForestClassifier(n_estimators = 100, max_depth = 7, \n",
    "#                                                               min_samples_leaf = 2,\n",
    "#                                                               warm_start = True, n_jobs=-1,\n",
    "#                                                               random_state = 75, verbose=False))),\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# в качестве мета-модели будем использовать LogisticRegression\n",
    "meta_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(verbose=False),\n",
    "    # final_estimator=RandomForestClassifier(n_estimators = 10_000, \n",
    "                                           # max_depth = 5,\n",
    "                                           # verbose=False),\n",
    "    n_jobs=-1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "stacking_classifier = meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad5edcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:03:43] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:03:43] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:03:43] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:03:43] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:03:43] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;ExtraTrees&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                                 ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                                   SimpleImputer()),\n",
       "                                                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  [&#x27;0&#x27;,\n",
       "                                                                                   &#x27;1&#x27;,\n",
       "                                                                                   &#x27;2&#x27;,\n",
       "                                                                                   &#x27;3&#x27;,\n",
       "                                                                                   &#x27;4&#x27;,\n",
       "                                                                                   &#x27;5&#x27;,\n",
       "                                                                                   &#x27;6&#x27;,\n",
       "                                                                                   &#x27;7&#x27;,\n",
       "                                                                                   &#x27;8&#x27;,\n",
       "                                                                                   &#x27;9&#x27;,\n",
       "                                                                                   &#x27;10&#x27;,\n",
       "                                                                                   &#x27;11&#x27;,\n",
       "                                                                                   &#x27;12&#x27;,\n",
       "                                                                                   &#x27;13&#x27;,\n",
       "                                                                                   &#x27;14&#x27;,\n",
       "                                                                                   &#x27;15&#x27;,\n",
       "                                                                                   &#x27;16&#x27;,\n",
       "                                                                                   &#x27;17&#x27;,\n",
       "                                                                                   &#x27;18&#x27;,\n",
       "                                                                                   &#x27;19&#x27;,\n",
       "                                                                                   &#x27;20&#x27;,\n",
       "                                                                                   &#x27;21&#x27;,\n",
       "                                                                                   &#x27;22&#x27;,\n",
       "                                                                                   &#x27;23&#x27;,\n",
       "                                                                                   &#x27;24&#x27;,\n",
       "                                                                                   &#x27;25&#x27;,\n",
       "                                                                                   &#x27;26&#x27;,\n",
       "                                                                                   &#x27;27&#x27;,\n",
       "                                                                                   &#x27;28&#x27;,\n",
       "                                                                                   &#x27;29&#x27;, ...]),\n",
       "                                                                                 (&#x27;...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=0.1, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=200, n_jobs=None,\n",
       "                                              num_parallel_tree=None, ...)),\n",
       "                               (&#x27;CatBoost&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x7fecba05c5e0&gt;)],\n",
       "                   final_estimator=LogisticRegression(verbose=False), n_jobs=-1,\n",
       "                   verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;ExtraTrees&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                                 ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                                   SimpleImputer()),\n",
       "                                                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  [&#x27;0&#x27;,\n",
       "                                                                                   &#x27;1&#x27;,\n",
       "                                                                                   &#x27;2&#x27;,\n",
       "                                                                                   &#x27;3&#x27;,\n",
       "                                                                                   &#x27;4&#x27;,\n",
       "                                                                                   &#x27;5&#x27;,\n",
       "                                                                                   &#x27;6&#x27;,\n",
       "                                                                                   &#x27;7&#x27;,\n",
       "                                                                                   &#x27;8&#x27;,\n",
       "                                                                                   &#x27;9&#x27;,\n",
       "                                                                                   &#x27;10&#x27;,\n",
       "                                                                                   &#x27;11&#x27;,\n",
       "                                                                                   &#x27;12&#x27;,\n",
       "                                                                                   &#x27;13&#x27;,\n",
       "                                                                                   &#x27;14&#x27;,\n",
       "                                                                                   &#x27;15&#x27;,\n",
       "                                                                                   &#x27;16&#x27;,\n",
       "                                                                                   &#x27;17&#x27;,\n",
       "                                                                                   &#x27;18&#x27;,\n",
       "                                                                                   &#x27;19&#x27;,\n",
       "                                                                                   &#x27;20&#x27;,\n",
       "                                                                                   &#x27;21&#x27;,\n",
       "                                                                                   &#x27;22&#x27;,\n",
       "                                                                                   &#x27;23&#x27;,\n",
       "                                                                                   &#x27;24&#x27;,\n",
       "                                                                                   &#x27;25&#x27;,\n",
       "                                                                                   &#x27;26&#x27;,\n",
       "                                                                                   &#x27;27&#x27;,\n",
       "                                                                                   &#x27;28&#x27;,\n",
       "                                                                                   &#x27;29&#x27;, ...]),\n",
       "                                                                                 (&#x27;...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=0.1, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=200, n_jobs=None,\n",
       "                                              num_parallel_tree=None, ...)),\n",
       "                               (&#x27;CatBoost&#x27;,\n",
       "                                &lt;catboost.core.CatBoostClassifier object at 0x7fecba05c5e0&gt;)],\n",
       "                   final_estimator=LogisticRegression(verbose=False), n_jobs=-1,\n",
       "                   verbose=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ExtraTrees</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;,\n",
       "                                  &#x27;9&#x27;, &#x27;10&#x27;, &#x27;11&#x27;, &#x27;12&#x27;, &#x27;13&#x27;, &#x27;14&#x27;, &#x27;15&#x27;, &#x27;16&#x27;,\n",
       "                                  &#x27;17&#x27;, &#x27;18&#x27;, &#x27;19&#x27;, &#x27;20&#x27;, &#x27;21&#x27;, &#x27;22&#x27;, &#x27;23&#x27;,\n",
       "                                  &#x27;24&#x27;, &#x27;25&#x27;, &#x27;26&#x27;, &#x27;27&#x27;, &#x27;28&#x27;, &#x27;29&#x27;, ...]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;10&#x27;, &#x27;11&#x27;, &#x27;12&#x27;, &#x27;13&#x27;, &#x27;14&#x27;, &#x27;15&#x27;, &#x27;16&#x27;, &#x27;17&#x27;, &#x27;18&#x27;, &#x27;19&#x27;, &#x27;20&#x27;, &#x27;21&#x27;, &#x27;22&#x27;, &#x27;23&#x27;, &#x27;24&#x27;, &#x27;25&#x27;, &#x27;26&#x27;, &#x27;27&#x27;, &#x27;28&#x27;, &#x27;29&#x27;, &#x27;30&#x27;, &#x27;31&#x27;, &#x27;32&#x27;, &#x27;33&#x27;, &#x27;34&#x27;, &#x27;35&#x27;, &#x27;36&#x27;, &#x27;37&#x27;, &#x27;38&#x27;, &#x27;39&#x27;, &#x27;40&#x27;, &#x27;41&#x27;, &#x27;42&#x27;, &#x27;43&#x27;, &#x27;44&#x27;, &#x27;45&#x27;, &#x27;46&#x27;, &#x27;47&#x27;, &#x27;48&#x27;, &#x27;49&#x27;, &#x27;50&#x27;, &#x27;51&#x27;, &#x27;52&#x27;, &#x27;53&#x27;, &#x27;54&#x27;, &#x27;55&#x27;, &#x27;56&#x27;, &#x27;57&#x27;, &#x27;58&#x27;, &#x27;59&#x27;, &#x27;60&#x27;, &#x27;61&#x27;, &#x27;62&#x27;, &#x27;63&#x27;, &#x27;64&#x27;, &#x27;65&#x27;, &#x27;66&#x27;, &#x27;67&#x27;, &#x27;68&#x27;, &#x27;69&#x27;, &#x27;70&#x27;, &#x27;71&#x27;, &#x27;72&#x27;, &#x27;73&#x27;, &#x27;74&#x27;, &#x27;75&#x27;, &#x27;76&#x27;, &#x27;77&#x27;, &#x27;78&#x27;, &#x27;79&#x27;, &#x27;80&#x27;, &#x27;81&#x27;, &#x27;82&#x27;, &#x27;83&#x27;, &#x27;84&#x27;, &#x27;85&#x27;, &#x27;86&#x27;, &#x27;87&#x27;, &#x27;88&#x27;, &#x27;89&#x27;, &#x27;90&#x27;, &#x27;91&#x27;, &#x27;92&#x27;, &#x27;93&#x27;, &#x27;94&#x27;, &#x27;95&#x27;, &#x27;96&#x27;, &#x27;97&#x27;, &#x27;98&#x27;, &#x27;99&#x27;, &#x27;100&#x27;, &#x27;101&#x27;, &#x27;102&#x27;, &#x27;103&#x27;, &#x27;104&#x27;, &#x27;105&#x27;, &#x27;106&#x27;, &#x27;107&#x27;, &#x27;108&#x27;, &#x27;109&#x27;, &#x27;110&#x27;, &#x27;111&#x27;, &#x27;112&#x27;, &#x27;113&#x27;, &#x27;114&#x27;, &#x27;115&#x27;, &#x27;116&#x27;, &#x27;117&#x27;, &#x27;118&#x27;, &#x27;119&#x27;, &#x27;120&#x27;, &#x27;121&#x27;, &#x27;122&#x27;, &#x27;123&#x27;, &#x27;124&#x27;, &#x27;125&#x27;, &#x27;126&#x27;, &#x27;127&#x27;, &#x27;128&#x27;, &#x27;129&#x27;, &#x27;130&#x27;, &#x27;131&#x27;, &#x27;132&#x27;, &#x27;133&#x27;, &#x27;134&#x27;, &#x27;135&#x27;, &#x27;136&#x27;, &#x27;137&#x27;, &#x27;138&#x27;, &#x27;139&#x27;, &#x27;140&#x27;, &#x27;141&#x27;, &#x27;142&#x27;, &#x27;143&#x27;, &#x27;144&#x27;, &#x27;145&#x27;, &#x27;146&#x27;, &#x27;147&#x27;, &#x27;148&#x27;, &#x27;149&#x27;, &#x27;150&#x27;, &#x27;151&#x27;, &#x27;152&#x27;, &#x27;153&#x27;, &#x27;154&#x27;, &#x27;155&#x27;, &#x27;156&#x27;, &#x27;157&#x27;, &#x27;158&#x27;, &#x27;159&#x27;, &#x27;160&#x27;, &#x27;161&#x27;, &#x27;162&#x27;, &#x27;163&#x27;, &#x27;164&#x27;, &#x27;165&#x27;, &#x27;166&#x27;, &#x27;167&#x27;, &#x27;168&#x27;, &#x27;169&#x27;, &#x27;170&#x27;, &#x27;171&#x27;, &#x27;172&#x27;, &#x27;173&#x27;, &#x27;174&#x27;, &#x27;175&#x27;, &#x27;176&#x27;, &#x27;177&#x27;, &#x27;178&#x27;, &#x27;179&#x27;, &#x27;180&#x27;, &#x27;181&#x27;, &#x27;182&#x27;, &#x27;183&#x27;, &#x27;184&#x27;, &#x27;185&#x27;, &#x27;186&#x27;, &#x27;187&#x27;, &#x27;188&#x27;, &#x27;189&#x27;, &#x27;190&#x27;, &#x27;191&#x27;, &#x27;192&#x27;, &#x27;193&#x27;, &#x27;194&#x27;, &#x27;195&#x27;, &#x27;196&#x27;, &#x27;197&#x27;, &#x27;198&#x27;, &#x27;199&#x27;, &#x27;200&#x27;, &#x27;201&#x27;, &#x27;202&#x27;, &#x27;203&#x27;, &#x27;204&#x27;, &#x27;205&#x27;, &#x27;206&#x27;, &#x27;207&#x27;, &#x27;208&#x27;, &#x27;209&#x27;, &#x27;210&#x27;, &#x27;211&#x27;, &#x27;212&#x27;, &#x27;213&#x27;, &#x27;214&#x27;, &#x27;215&#x27;, &#x27;216&#x27;, &#x27;217&#x27;, &#x27;218&#x27;, &#x27;219&#x27;, &#x27;220&#x27;, &#x27;221&#x27;, &#x27;222&#x27;, &#x27;223&#x27;, &#x27;224&#x27;, &#x27;225&#x27;, &#x27;226&#x27;, &#x27;227&#x27;, &#x27;228&#x27;, &#x27;229&#x27;, &#x27;230&#x27;, &#x27;231&#x27;, &#x27;232&#x27;, &#x27;233&#x27;, &#x27;234&#x27;, &#x27;235&#x27;, &#x27;236&#x27;, &#x27;237&#x27;, &#x27;238&#x27;, &#x27;239&#x27;, &#x27;240&#x27;, &#x27;241&#x27;, &#x27;242&#x27;, &#x27;243&#x27;, &#x27;244&#x27;, &#x27;245&#x27;, &#x27;246&#x27;, &#x27;247&#x27;, &#x27;248&#x27;, &#x27;249&#x27;, &#x27;250&#x27;, &#x27;251&#x27;, &#x27;252&#x27;, &#x27;253&#x27;, &#x27;254&#x27;, &#x27;255&#x27;, &#x27;256&#x27;, &#x27;257&#x27;, &#x27;258&#x27;, &#x27;259&#x27;, &#x27;260&#x27;, &#x27;261&#x27;, &#x27;262&#x27;, &#x27;263&#x27;, &#x27;264&#x27;, &#x27;265&#x27;, &#x27;266&#x27;, &#x27;267&#x27;, &#x27;268&#x27;, &#x27;269&#x27;, &#x27;270&#x27;, &#x27;271&#x27;, &#x27;272&#x27;, &#x27;273&#x27;, &#x27;274&#x27;, &#x27;275&#x27;, &#x27;276&#x27;, &#x27;277&#x27;, &#x27;278&#x27;, &#x27;279&#x27;, &#x27;280&#x27;, &#x27;281&#x27;, &#x27;282&#x27;, &#x27;283&#x27;, &#x27;284&#x27;, &#x27;285&#x27;, &#x27;286&#x27;, &#x27;287&#x27;, &#x27;288&#x27;, &#x27;289&#x27;, &#x27;290&#x27;, &#x27;291&#x27;, &#x27;292&#x27;, &#x27;293&#x27;, &#x27;294&#x27;, &#x27;295&#x27;, &#x27;296&#x27;, &#x27;297&#x27;, &#x27;298&#x27;, &#x27;299&#x27;, &#x27;300&#x27;, &#x27;301&#x27;, &#x27;302&#x27;, &#x27;303&#x27;, &#x27;304&#x27;, &#x27;305&#x27;, &#x27;306&#x27;, &#x27;307&#x27;, &#x27;308&#x27;, &#x27;309&#x27;, &#x27;310&#x27;, &#x27;311&#x27;, &#x27;312&#x27;, &#x27;313&#x27;, &#x27;314&#x27;, &#x27;315&#x27;, &#x27;316&#x27;, &#x27;317&#x27;, &#x27;318&#x27;, &#x27;319&#x27;, &#x27;320&#x27;, &#x27;321&#x27;, &#x27;322&#x27;, &#x27;323&#x27;, &#x27;324&#x27;, &#x27;325&#x27;, &#x27;326&#x27;, &#x27;327&#x27;, &#x27;328&#x27;, &#x27;329&#x27;, &#x27;330&#x27;, &#x27;331&#x27;, &#x27;332&#x27;, &#x27;333&#x27;, &#x27;334&#x27;, &#x27;335&#x27;, &#x27;336&#x27;, &#x27;337&#x27;, &#x27;338&#x27;, &#x27;339&#x27;, &#x27;340&#x27;, &#x27;341&#x27;, &#x27;342&#x27;, &#x27;343&#x27;, &#x27;344&#x27;, &#x27;345&#x27;, &#x27;346&#x27;, &#x27;347&#x27;, &#x27;348&#x27;, &#x27;349&#x27;, &#x27;350&#x27;, &#x27;351&#x27;, &#x27;352&#x27;, &#x27;353&#x27;, &#x27;354&#x27;, &#x27;355&#x27;, &#x27;356&#x27;, &#x27;357&#x27;, &#x27;358&#x27;, &#x27;359&#x27;, &#x27;360&#x27;, &#x27;361&#x27;, &#x27;362&#x27;, &#x27;363&#x27;, &#x27;364&#x27;, &#x27;365&#x27;, &#x27;366&#x27;, &#x27;367&#x27;, &#x27;368&#x27;, &#x27;369&#x27;, &#x27;370&#x27;, &#x27;371&#x27;, &#x27;372&#x27;, &#x27;373&#x27;, &#x27;374&#x27;, &#x27;375&#x27;, &#x27;376&#x27;, &#x27;377&#x27;, &#x27;378&#x27;, &#x27;379&#x27;, &#x27;380&#x27;, &#x27;381&#x27;, &#x27;382&#x27;, &#x27;383&#x27;, &#x27;384&#x27;, &#x27;385&#x27;, &#x27;386&#x27;, &#x27;387&#x27;, &#x27;388&#x27;, &#x27;389&#x27;, &#x27;390&#x27;, &#x27;391&#x27;, &#x27;392&#x27;, &#x27;393&#x27;, &#x27;394&#x27;, &#x27;395&#x27;, &#x27;396&#x27;, &#x27;397&#x27;, &#x27;398&#x27;, &#x27;399&#x27;, &#x27;400&#x27;, &#x27;401&#x27;, &#x27;402&#x27;, &#x27;403&#x27;, &#x27;404&#x27;, &#x27;405&#x27;, &#x27;406&#x27;, &#x27;407&#x27;, &#x27;408&#x27;, &#x27;409&#x27;, &#x27;410&#x27;, &#x27;411&#x27;, &#x27;412&#x27;, &#x27;413&#x27;, &#x27;414&#x27;, &#x27;415&#x27;, &#x27;416&#x27;, &#x27;417&#x27;, &#x27;418&#x27;, &#x27;419&#x27;, &#x27;420&#x27;, &#x27;421&#x27;, &#x27;422&#x27;, &#x27;423&#x27;, &#x27;424&#x27;, &#x27;425&#x27;, &#x27;426&#x27;, &#x27;427&#x27;, &#x27;428&#x27;, &#x27;429&#x27;, &#x27;430&#x27;, &#x27;431&#x27;, &#x27;432&#x27;, &#x27;433&#x27;, &#x27;434&#x27;, &#x27;435&#x27;, &#x27;436&#x27;, &#x27;437&#x27;, &#x27;438&#x27;, &#x27;439&#x27;, &#x27;440&#x27;, &#x27;441&#x27;, &#x27;442&#x27;, &#x27;443&#x27;, &#x27;444&#x27;, &#x27;445&#x27;, &#x27;446&#x27;, &#x27;447&#x27;, &#x27;448&#x27;, &#x27;449&#x27;, &#x27;450&#x27;, &#x27;451&#x27;, &#x27;452&#x27;, &#x27;453&#x27;, &#x27;454&#x27;, &#x27;455&#x27;, &#x27;456&#x27;, &#x27;457&#x27;, &#x27;458&#x27;, &#x27;459&#x27;, &#x27;460&#x27;, &#x27;461&#x27;, &#x27;462&#x27;, &#x27;463&#x27;, &#x27;464&#x27;, &#x27;465&#x27;, &#x27;466&#x27;, &#x27;467&#x27;, &#x27;468&#x27;, &#x27;469&#x27;, &#x27;470&#x27;, &#x27;471&#x27;, &#x27;472&#x27;, &#x27;473&#x27;, &#x27;474&#x27;, &#x27;475&#x27;, &#x27;476&#x27;, &#x27;477&#x27;, &#x27;478&#x27;, &#x27;479&#x27;, &#x27;480&#x27;, &#x27;481&#x27;, &#x27;482&#x27;, &#x27;483&#x27;, &#x27;484&#x27;, &#x27;485&#x27;, &#x27;486&#x27;, &#x27;487&#x27;, &#x27;488&#x27;, &#x27;489&#x27;, &#x27;490&#x27;, &#x27;491&#x27;, &#x27;492&#x27;, &#x27;493&#x27;, &#x27;494&#x27;, &#x27;495&#x27;, &#x27;496&#x27;, &#x27;497&#x27;, &#x27;498&#x27;, &#x27;499&#x27;, &#x27;500&#x27;, &#x27;501&#x27;, &#x27;502&#x27;, &#x27;503&#x27;, &#x27;504&#x27;, &#x27;505&#x27;, &#x27;506&#x27;, &#x27;507&#x27;, &#x27;508&#x27;, &#x27;509&#x27;, &#x27;510&#x27;, &#x27;511&#x27;, &#x27;512&#x27;, &#x27;513&#x27;, &#x27;514&#x27;, &#x27;515&#x27;, &#x27;516&#x27;, &#x27;517&#x27;, &#x27;518&#x27;, &#x27;519&#x27;, &#x27;520&#x27;, &#x27;521&#x27;, &#x27;522&#x27;, &#x27;523&#x27;, &#x27;524&#x27;, &#x27;525&#x27;, &#x27;526&#x27;, &#x27;527&#x27;, &#x27;528&#x27;, &#x27;529&#x27;, &#x27;530&#x27;, &#x27;531&#x27;, &#x27;532&#x27;, &#x27;533&#x27;, &#x27;534&#x27;, &#x27;535&#x27;, &#x27;536&#x27;, &#x27;537&#x27;, &#x27;538&#x27;, &#x27;539&#x27;, &#x27;540&#x27;, &#x27;541&#x27;, &#x27;542&#x27;, &#x27;543&#x27;, &#x27;544&#x27;, &#x27;545&#x27;, &#x27;546&#x27;, &#x27;547&#x27;, &#x27;548&#x27;, &#x27;549&#x27;, &#x27;550&#x27;, &#x27;551&#x27;, &#x27;552&#x27;, &#x27;553&#x27;, &#x27;554&#x27;, &#x27;555&#x27;, &#x27;556&#x27;, &#x27;557&#x27;, &#x27;558&#x27;, &#x27;559&#x27;, &#x27;560&#x27;, &#x27;561&#x27;, &#x27;562&#x27;, &#x27;563&#x27;, &#x27;564&#x27;, &#x27;565&#x27;, &#x27;566&#x27;, &#x27;567&#x27;, &#x27;568&#x27;, &#x27;569&#x27;, &#x27;570&#x27;, &#x27;571&#x27;, &#x27;572&#x27;, &#x27;573&#x27;, &#x27;574&#x27;, &#x27;575&#x27;, &#x27;576&#x27;, &#x27;577&#x27;, &#x27;578&#x27;, &#x27;579&#x27;, &#x27;580&#x27;, &#x27;581&#x27;, &#x27;582&#x27;, &#x27;583&#x27;, &#x27;584&#x27;, &#x27;585&#x27;, &#x27;586&#x27;, &#x27;587&#x27;, &#x27;588&#x27;, &#x27;589&#x27;, &#x27;590&#x27;, &#x27;591&#x27;, &#x27;592&#x27;, &#x27;593&#x27;, &#x27;594&#x27;, &#x27;595&#x27;, &#x27;596&#x27;, &#x27;597&#x27;, &#x27;598&#x27;, &#x27;599&#x27;, &#x27;600&#x27;, &#x27;601&#x27;, &#x27;602&#x27;, &#x27;603&#x27;, &#x27;604&#x27;, &#x27;605&#x27;, &#x27;606&#x27;, &#x27;607&#x27;, &#x27;608&#x27;, &#x27;609&#x27;, &#x27;610&#x27;, &#x27;611&#x27;, &#x27;612&#x27;, &#x27;613&#x27;, &#x27;614&#x27;, &#x27;615&#x27;, &#x27;616&#x27;, &#x27;617&#x27;, &#x27;618&#x27;, &#x27;619&#x27;, &#x27;620&#x27;, &#x27;621&#x27;, &#x27;622&#x27;, &#x27;623&#x27;, &#x27;624&#x27;, &#x27;625&#x27;, &#x27;626&#x27;, &#x27;627&#x27;, &#x27;628&#x27;, &#x27;629&#x27;, &#x27;630&#x27;, &#x27;631&#x27;, &#x27;632&#x27;, &#x27;633&#x27;, &#x27;634&#x27;, &#x27;635&#x27;, &#x27;636&#x27;, &#x27;637&#x27;, &#x27;638&#x27;, &#x27;639&#x27;, &#x27;640&#x27;, &#x27;641&#x27;, &#x27;642&#x27;, &#x27;643&#x27;, &#x27;644&#x27;, &#x27;645&#x27;, &#x27;646&#x27;, &#x27;647&#x27;, &#x27;648&#x27;, &#x27;649&#x27;, &#x27;650&#x27;, &#x27;651&#x27;, &#x27;652&#x27;, &#x27;653&#x27;, &#x27;654&#x27;, &#x27;655&#x27;, &#x27;656&#x27;, &#x27;657&#x27;, &#x27;658&#x27;, &#x27;659&#x27;, &#x27;660&#x27;, &#x27;661&#x27;, &#x27;662&#x27;, &#x27;663&#x27;, &#x27;664&#x27;, &#x27;665&#x27;, &#x27;666&#x27;, &#x27;667&#x27;, &#x27;668&#x27;, &#x27;669&#x27;, &#x27;670&#x27;, &#x27;671&#x27;, &#x27;672&#x27;, &#x27;673&#x27;, &#x27;674&#x27;, &#x27;675&#x27;, &#x27;676&#x27;, &#x27;677&#x27;, &#x27;678&#x27;, &#x27;679&#x27;, &#x27;680&#x27;, &#x27;681&#x27;, &#x27;682&#x27;, &#x27;683&#x27;, &#x27;684&#x27;, &#x27;685&#x27;, &#x27;686&#x27;, &#x27;687&#x27;, &#x27;688&#x27;, &#x27;689&#x27;, &#x27;690&#x27;, &#x27;691&#x27;, &#x27;692&#x27;, &#x27;693&#x27;, &#x27;694&#x27;, &#x27;695&#x27;, &#x27;696&#x27;, &#x27;697&#x27;, &#x27;698&#x27;, &#x27;699&#x27;, &#x27;700&#x27;, &#x27;701&#x27;, &#x27;702&#x27;, &#x27;703&#x27;, &#x27;704&#x27;, &#x27;705&#x27;, &#x27;706&#x27;, &#x27;707&#x27;, &#x27;708&#x27;, &#x27;709&#x27;, &#x27;710&#x27;, &#x27;711&#x27;, &#x27;712&#x27;, &#x27;713&#x27;, &#x27;714&#x27;, &#x27;715&#x27;, &#x27;716&#x27;, &#x27;717&#x27;, &#x27;718&#x27;, &#x27;719&#x27;, &#x27;720&#x27;, &#x27;721&#x27;, &#x27;722&#x27;, &#x27;723&#x27;, &#x27;724&#x27;, &#x27;725&#x27;, &#x27;726&#x27;, &#x27;727&#x27;, &#x27;728&#x27;, &#x27;729&#x27;, &#x27;730&#x27;, &#x27;731&#x27;, &#x27;732&#x27;, &#x27;733&#x27;, &#x27;734&#x27;, &#x27;735&#x27;, &#x27;736&#x27;, &#x27;737&#x27;, &#x27;738&#x27;, &#x27;739&#x27;, &#x27;740&#x27;, &#x27;741&#x27;, &#x27;742&#x27;, &#x27;743&#x27;, &#x27;744&#x27;, &#x27;745&#x27;, &#x27;746&#x27;, &#x27;747&#x27;, &#x27;748&#x27;, &#x27;749&#x27;, &#x27;750&#x27;, &#x27;751&#x27;, &#x27;752&#x27;, &#x27;753&#x27;, &#x27;754&#x27;, &#x27;755&#x27;, &#x27;756&#x27;, &#x27;757&#x27;, &#x27;758&#x27;, &#x27;759&#x27;, &#x27;760&#x27;, &#x27;761&#x27;, &#x27;762&#x27;, &#x27;763&#x27;, &#x27;764&#x27;, &#x27;765&#x27;, &#x27;766&#x27;, &#x27;767&#x27;, &#x27;768&#x27;, &#x27;769&#x27;, &#x27;770&#x27;, &#x27;771&#x27;, &#x27;772&#x27;, &#x27;773&#x27;, &#x27;774&#x27;, &#x27;775&#x27;, &#x27;776&#x27;, &#x27;777&#x27;, &#x27;778&#x27;, &#x27;779&#x27;, &#x27;780&#x27;, &#x27;781&#x27;, &#x27;782&#x27;, &#x27;783&#x27;, &#x27;784&#x27;, &#x27;785&#x27;, &#x27;786&#x27;, &#x27;787&#x27;, &#x27;788&#x27;, &#x27;789&#x27;, &#x27;790&#x27;, &#x27;791&#x27;, &#x27;792&#x27;, &#x27;793&#x27;, &#x27;794&#x27;, &#x27;795&#x27;, &#x27;796&#x27;, &#x27;797&#x27;, &#x27;798&#x27;, &#x27;799&#x27;, &#x27;800&#x27;, &#x27;801&#x27;, &#x27;802&#x27;, &#x27;803&#x27;, &#x27;804&#x27;, &#x27;805&#x27;, &#x27;806&#x27;, &#x27;807&#x27;, &#x27;808&#x27;, &#x27;809&#x27;, &#x27;810&#x27;, &#x27;811&#x27;, &#x27;812&#x27;, &#x27;813&#x27;, &#x27;814&#x27;, &#x27;815&#x27;, &#x27;816&#x27;, &#x27;817&#x27;, &#x27;818&#x27;, &#x27;819&#x27;, &#x27;820&#x27;, &#x27;821&#x27;, &#x27;822&#x27;, &#x27;823&#x27;, &#x27;824&#x27;, &#x27;825&#x27;, &#x27;826&#x27;, &#x27;827&#x27;, &#x27;828&#x27;, &#x27;829&#x27;, &#x27;830&#x27;, &#x27;831&#x27;, &#x27;832&#x27;, &#x27;833&#x27;, &#x27;834&#x27;, &#x27;835&#x27;, &#x27;836&#x27;, &#x27;837&#x27;, &#x27;838&#x27;, &#x27;839&#x27;, &#x27;840&#x27;, &#x27;841&#x27;, &#x27;842&#x27;, &#x27;843&#x27;, &#x27;844&#x27;, &#x27;845&#x27;, &#x27;846&#x27;, &#x27;847&#x27;, &#x27;848&#x27;, &#x27;849&#x27;, &#x27;850&#x27;, &#x27;851&#x27;, &#x27;852&#x27;, &#x27;853&#x27;, &#x27;854&#x27;, &#x27;855&#x27;, &#x27;856&#x27;, &#x27;857&#x27;, &#x27;858&#x27;, &#x27;859&#x27;, &#x27;860&#x27;, &#x27;861&#x27;, &#x27;862&#x27;, &#x27;863&#x27;, &#x27;864&#x27;, &#x27;865&#x27;, &#x27;866&#x27;, &#x27;867&#x27;, &#x27;868&#x27;, &#x27;869&#x27;, &#x27;870&#x27;, &#x27;871&#x27;, &#x27;872&#x27;, &#x27;873&#x27;, &#x27;874&#x27;, &#x27;875&#x27;, &#x27;876&#x27;, &#x27;877&#x27;, &#x27;878&#x27;, &#x27;879&#x27;, &#x27;880&#x27;, &#x27;881&#x27;, &#x27;882&#x27;, &#x27;883&#x27;, &#x27;884&#x27;, &#x27;885&#x27;, &#x27;886&#x27;, &#x27;887&#x27;, &#x27;888&#x27;, &#x27;889&#x27;, &#x27;890&#x27;, &#x27;891&#x27;, &#x27;892&#x27;, &#x27;893&#x27;, &#x27;894&#x27;, &#x27;895&#x27;, &#x27;896&#x27;, &#x27;897&#x27;, &#x27;898&#x27;, &#x27;899&#x27;, &#x27;900&#x27;, &#x27;901&#x27;, &#x27;902&#x27;, &#x27;903&#x27;, &#x27;904&#x27;, &#x27;905&#x27;, &#x27;906&#x27;, &#x27;907&#x27;, &#x27;908&#x27;, &#x27;909&#x27;, &#x27;910&#x27;, &#x27;911&#x27;, &#x27;912&#x27;, &#x27;913&#x27;, &#x27;914&#x27;, &#x27;915&#x27;, &#x27;916&#x27;, &#x27;917&#x27;, &#x27;918&#x27;, &#x27;919&#x27;, &#x27;920&#x27;, &#x27;921&#x27;, &#x27;922&#x27;, &#x27;923&#x27;, &#x27;924&#x27;, &#x27;925&#x27;, &#x27;926&#x27;, &#x27;927&#x27;, &#x27;928&#x27;, &#x27;929&#x27;, &#x27;930&#x27;, &#x27;931&#x27;, &#x27;932&#x27;, &#x27;933&#x27;, &#x27;934&#x27;, &#x27;935&#x27;, &#x27;936&#x27;, &#x27;937&#x27;, &#x27;938&#x27;, &#x27;939&#x27;, &#x27;940&#x27;, &#x27;941&#x27;, &#x27;942&#x27;, &#x27;943&#x27;, &#x27;944&#x27;, &#x27;945&#x27;, &#x27;946&#x27;, &#x27;947&#x27;, &#x27;948&#x27;, &#x27;949&#x27;, &#x27;950&#x27;, &#x27;951&#x27;, &#x27;952&#x27;, &#x27;953&#x27;, &#x27;954&#x27;, &#x27;955&#x27;, &#x27;956&#x27;, &#x27;957&#x27;, &#x27;958&#x27;, &#x27;959&#x27;, &#x27;960&#x27;, &#x27;961&#x27;, &#x27;962&#x27;, &#x27;963&#x27;, &#x27;964&#x27;, &#x27;965&#x27;, &#x27;966&#x27;, &#x27;967&#x27;, &#x27;968&#x27;, &#x27;969&#x27;, &#x27;970&#x27;, &#x27;971&#x27;, &#x27;972&#x27;, &#x27;973&#x27;, &#x27;974&#x27;, &#x27;975&#x27;, &#x27;976&#x27;, &#x27;977&#x27;, &#x27;978&#x27;, &#x27;979&#x27;, &#x27;980&#x27;, &#x27;981&#x27;, &#x27;982&#x27;, &#x27;983&#x27;, &#x27;984&#x27;, &#x27;985&#x27;, &#x27;986&#x27;, &#x27;987&#x27;, &#x27;988&#x27;, &#x27;989&#x27;, &#x27;990&#x27;, &#x27;991&#x27;, &#x27;992&#x27;, &#x27;993&#x27;, &#x27;994&#x27;, &#x27;995&#x27;, &#x27;996&#x27;, &#x27;997&#x27;, &#x27;998&#x27;, &#x27;999&#x27;, &#x27;1000&#x27;, &#x27;1001&#x27;, &#x27;1002&#x27;, &#x27;1003&#x27;, &#x27;1004&#x27;, &#x27;1005&#x27;, &#x27;1006&#x27;, &#x27;1007&#x27;, &#x27;1008&#x27;, &#x27;1009&#x27;, &#x27;1010&#x27;, &#x27;1011&#x27;, &#x27;1012&#x27;, &#x27;1013&#x27;, &#x27;1014&#x27;, &#x27;1015&#x27;, &#x27;1016&#x27;, &#x27;1017&#x27;, &#x27;1018&#x27;, &#x27;1019&#x27;, &#x27;1020&#x27;, &#x27;1021&#x27;, &#x27;1022&#x27;, &#x27;1023&#x27;, &#x27;1024&#x27;, &#x27;1025&#x27;, &#x27;1026&#x27;, &#x27;1027&#x27;, &#x27;1028&#x27;, &#x27;1029&#x27;, &#x27;1030&#x27;, &#x27;1031&#x27;, &#x27;1032&#x27;, &#x27;1033&#x27;, &#x27;1034&#x27;, &#x27;1035&#x27;, &#x27;1036&#x27;, &#x27;1037&#x27;, &#x27;1038&#x27;, &#x27;1039&#x27;, &#x27;1040&#x27;, &#x27;1041&#x27;, &#x27;1042&#x27;, &#x27;1043&#x27;, &#x27;1044&#x27;, &#x27;1045&#x27;, &#x27;1046&#x27;, &#x27;1047&#x27;, &#x27;1048&#x27;, &#x27;1049&#x27;, &#x27;1050&#x27;, &#x27;1051&#x27;, &#x27;1052&#x27;, &#x27;1053&#x27;, &#x27;1054&#x27;, &#x27;1055&#x27;, &#x27;1056&#x27;, &#x27;1057&#x27;, &#x27;1058&#x27;, &#x27;1059&#x27;, &#x27;1060&#x27;, &#x27;1061&#x27;, &#x27;1062&#x27;, &#x27;1063&#x27;, &#x27;1064&#x27;, &#x27;1065&#x27;, &#x27;1066&#x27;, &#x27;1067&#x27;, &#x27;1068&#x27;, &#x27;1069&#x27;, &#x27;1070&#x27;, &#x27;1071&#x27;, &#x27;1072&#x27;, &#x27;1073&#x27;, &#x27;1074&#x27;, &#x27;1075&#x27;, &#x27;1076&#x27;, &#x27;1077&#x27;, &#x27;1078&#x27;, &#x27;1079&#x27;, &#x27;1080&#x27;, &#x27;1081&#x27;, &#x27;1082&#x27;, &#x27;1083&#x27;, &#x27;1084&#x27;, &#x27;1085&#x27;, &#x27;1086&#x27;, &#x27;1087&#x27;, &#x27;1088&#x27;, &#x27;1089&#x27;, &#x27;1090&#x27;, &#x27;1091&#x27;, &#x27;1092&#x27;, &#x27;1093&#x27;, &#x27;1094&#x27;, &#x27;1095&#x27;, &#x27;1096&#x27;, &#x27;1097&#x27;, &#x27;1098&#x27;, &#x27;1099&#x27;, &#x27;1100&#x27;, &#x27;1101&#x27;, &#x27;1102&#x27;, &#x27;1103&#x27;, &#x27;1104&#x27;, &#x27;1105&#x27;, &#x27;1106&#x27;, &#x27;1107&#x27;, &#x27;1108&#x27;, &#x27;1109&#x27;, &#x27;1110&#x27;, &#x27;1111&#x27;, &#x27;1112&#x27;, &#x27;1113&#x27;, &#x27;1114&#x27;, &#x27;1115&#x27;, &#x27;1116&#x27;, &#x27;1117&#x27;, &#x27;1118&#x27;, &#x27;1119&#x27;, &#x27;1120&#x27;, &#x27;1121&#x27;, &#x27;1122&#x27;, &#x27;1123&#x27;, &#x27;1124&#x27;, &#x27;1125&#x27;, &#x27;1126&#x27;, &#x27;1127&#x27;, &#x27;1128&#x27;, &#x27;1129&#x27;, &#x27;1130&#x27;, &#x27;1131&#x27;, &#x27;1132&#x27;, &#x27;1133&#x27;, &#x27;1134&#x27;, &#x27;1135&#x27;, &#x27;1136&#x27;, &#x27;1137&#x27;, &#x27;1138&#x27;, &#x27;1139&#x27;, &#x27;1140&#x27;, &#x27;1141&#x27;, &#x27;1142&#x27;, &#x27;1143&#x27;, &#x27;1144&#x27;, &#x27;1145&#x27;, &#x27;1146&#x27;, &#x27;1147&#x27;, &#x27;1148&#x27;, &#x27;1149&#x27;, &#x27;1150&#x27;, &#x27;1151&#x27;, &#x27;1152&#x27;, &#x27;1153&#x27;, &#x27;1154&#x27;, &#x27;1155&#x27;, &#x27;1156&#x27;, &#x27;1157&#x27;, &#x27;1158&#x27;, &#x27;1159&#x27;, &#x27;1160&#x27;, &#x27;1161&#x27;, &#x27;1162&#x27;, &#x27;1163&#x27;, &#x27;1164&#x27;, &#x27;1165&#x27;, &#x27;1166&#x27;, &#x27;1167&#x27;, &#x27;1168&#x27;, &#x27;1169&#x27;, &#x27;1170&#x27;, &#x27;1171&#x27;, &#x27;1172&#x27;, &#x27;1173&#x27;, &#x27;1174&#x27;, &#x27;1175&#x27;, &#x27;1176&#x27;, &#x27;1177&#x27;, &#x27;1178&#x27;, &#x27;1179&#x27;, &#x27;1180&#x27;, &#x27;1181&#x27;, &#x27;1182&#x27;, &#x27;1183&#x27;, &#x27;1184&#x27;, &#x27;1185&#x27;, &#x27;1186&#x27;, &#x27;1187&#x27;, &#x27;1188&#x27;, &#x27;1189&#x27;, &#x27;1190&#x27;, &#x27;1191&#x27;, &#x27;1192&#x27;, &#x27;1193&#x27;, &#x27;1194&#x27;, &#x27;1195&#x27;, &#x27;1196&#x27;, &#x27;1197&#x27;, &#x27;1198&#x27;, &#x27;1199&#x27;, &#x27;1200&#x27;, &#x27;1201&#x27;, &#x27;1202&#x27;, &#x27;1203&#x27;, &#x27;1204&#x27;, &#x27;1205&#x27;, &#x27;1206&#x27;, &#x27;1207&#x27;, &#x27;1208&#x27;, &#x27;1209&#x27;, &#x27;1210&#x27;, &#x27;1211&#x27;, &#x27;1212&#x27;, &#x27;1213&#x27;, &#x27;1214&#x27;, &#x27;1215&#x27;, &#x27;1216&#x27;, &#x27;1217&#x27;, &#x27;1218&#x27;, &#x27;1219&#x27;, &#x27;1220&#x27;, &#x27;1221&#x27;, &#x27;1222&#x27;, &#x27;1223&#x27;, &#x27;1224&#x27;, &#x27;1225&#x27;, &#x27;1226&#x27;, &#x27;1227&#x27;, &#x27;1228&#x27;, &#x27;1229&#x27;, &#x27;1230&#x27;, &#x27;1231&#x27;, &#x27;1232&#x27;, &#x27;1233&#x27;, &#x27;1234&#x27;, &#x27;1235&#x27;, &#x27;1236&#x27;, &#x27;1237&#x27;, &#x27;1238&#x27;, &#x27;1239&#x27;, &#x27;1240&#x27;, &#x27;1241&#x27;, &#x27;1242&#x27;, &#x27;1243&#x27;, &#x27;1244&#x27;, &#x27;1245&#x27;, &#x27;1246&#x27;, &#x27;1247&#x27;, &#x27;1248&#x27;, &#x27;1249&#x27;, &#x27;1250&#x27;, &#x27;1251&#x27;, &#x27;1252&#x27;, &#x27;1253&#x27;, &#x27;1254&#x27;, &#x27;1255&#x27;, &#x27;1256&#x27;, &#x27;1257&#x27;, &#x27;1258&#x27;, &#x27;1259&#x27;, &#x27;1260&#x27;, &#x27;1261&#x27;, &#x27;1262&#x27;, &#x27;1263&#x27;, &#x27;1264&#x27;, &#x27;1265&#x27;, &#x27;1266&#x27;, &#x27;1267&#x27;, &#x27;1268&#x27;, &#x27;1269&#x27;, &#x27;1270&#x27;, &#x27;1271&#x27;, &#x27;1272&#x27;, &#x27;1273&#x27;, &#x27;1274&#x27;, &#x27;1275&#x27;, &#x27;1276&#x27;, &#x27;1277&#x27;, &#x27;1278&#x27;, &#x27;1279&#x27;, &#x27;1280&#x27;, &#x27;1281&#x27;, &#x27;1282&#x27;, &#x27;1283&#x27;, &#x27;1284&#x27;, &#x27;1285&#x27;, &#x27;1286&#x27;, &#x27;1287&#x27;, &#x27;1288&#x27;, &#x27;1289&#x27;, &#x27;1290&#x27;, &#x27;1291&#x27;, &#x27;1292&#x27;, &#x27;1293&#x27;, &#x27;1294&#x27;, &#x27;1295&#x27;, &#x27;1296&#x27;, &#x27;1297&#x27;, &#x27;1298&#x27;, &#x27;1299&#x27;, &#x27;1300&#x27;, &#x27;1301&#x27;, &#x27;1302&#x27;, &#x27;1303&#x27;, &#x27;1304&#x27;, &#x27;1305&#x27;, &#x27;1306&#x27;, &#x27;1307&#x27;, &#x27;1308&#x27;, &#x27;1309&#x27;, &#x27;1310&#x27;, &#x27;1311&#x27;, &#x27;1312&#x27;, &#x27;1313&#x27;, &#x27;1314&#x27;, &#x27;1315&#x27;, &#x27;1316&#x27;, &#x27;1317&#x27;, &#x27;1318&#x27;, &#x27;1319&#x27;, &#x27;1320&#x27;, &#x27;1321&#x27;, &#x27;1322&#x27;, &#x27;1323&#x27;, &#x27;1324&#x27;, &#x27;1325&#x27;, &#x27;1326&#x27;, &#x27;1327&#x27;, &#x27;1328&#x27;, &#x27;1329&#x27;, &#x27;1330&#x27;, &#x27;1331&#x27;, &#x27;1332&#x27;, &#x27;1333&#x27;, &#x27;1334&#x27;, &#x27;1335&#x27;, &#x27;1336&#x27;, &#x27;1337&#x27;, &#x27;1338&#x27;, &#x27;1339&#x27;, &#x27;1340&#x27;, &#x27;1341&#x27;, &#x27;1342&#x27;, &#x27;1343&#x27;, &#x27;1344&#x27;, &#x27;1345&#x27;, &#x27;1346&#x27;, &#x27;1347&#x27;, &#x27;1348&#x27;, &#x27;1349&#x27;, &#x27;1350&#x27;, &#x27;1351&#x27;, &#x27;1352&#x27;, &#x27;1353&#x27;, &#x27;1354&#x27;, &#x27;1355&#x27;, &#x27;1356&#x27;, &#x27;1357&#x27;, &#x27;1358&#x27;, &#x27;1359&#x27;, &#x27;1360&#x27;, &#x27;1361&#x27;, &#x27;1362&#x27;, &#x27;1363&#x27;, &#x27;1364&#x27;, &#x27;1365&#x27;, &#x27;1366&#x27;, &#x27;1367&#x27;, &#x27;1368&#x27;, &#x27;1369&#x27;, &#x27;1370&#x27;, &#x27;1371&#x27;, &#x27;1372&#x27;, &#x27;1373&#x27;, &#x27;1374&#x27;, &#x27;1375&#x27;, &#x27;1376&#x27;, &#x27;1377&#x27;, &#x27;1378&#x27;, &#x27;1379&#x27;, &#x27;1380&#x27;, &#x27;1381&#x27;, &#x27;1382&#x27;, &#x27;1383&#x27;, &#x27;1384&#x27;, &#x27;1385&#x27;, &#x27;1386&#x27;, &#x27;1387&#x27;, &#x27;1388&#x27;, &#x27;1389&#x27;, &#x27;1390&#x27;, &#x27;1391&#x27;, &#x27;1392&#x27;, &#x27;1393&#x27;, &#x27;1394&#x27;, &#x27;1395&#x27;, &#x27;1396&#x27;, &#x27;1397&#x27;, &#x27;1398&#x27;, &#x27;1399&#x27;, &#x27;1400&#x27;, &#x27;1401&#x27;, &#x27;1402&#x27;, &#x27;1403&#x27;, &#x27;1404&#x27;, &#x27;1405&#x27;, &#x27;1406&#x27;, &#x27;1407&#x27;, &#x27;1408&#x27;, &#x27;1409&#x27;, &#x27;1410&#x27;, &#x27;1411&#x27;, &#x27;1412&#x27;, &#x27;1413&#x27;, &#x27;1414&#x27;, &#x27;1415&#x27;, &#x27;1416&#x27;, &#x27;1417&#x27;, &#x27;1418&#x27;, &#x27;1419&#x27;, &#x27;1420&#x27;, &#x27;1421&#x27;, &#x27;1422&#x27;, &#x27;1423&#x27;, &#x27;1424&#x27;, &#x27;1425&#x27;, &#x27;1426&#x27;, &#x27;1427&#x27;, &#x27;1428&#x27;, &#x27;1429&#x27;, &#x27;1430&#x27;, &#x27;1431&#x27;, &#x27;1432&#x27;, &#x27;1433&#x27;, &#x27;1434&#x27;, &#x27;1435&#x27;, &#x27;1436&#x27;, &#x27;1437&#x27;, &#x27;1438&#x27;, &#x27;1439&#x27;, &#x27;1440&#x27;, &#x27;1441&#x27;, &#x27;1442&#x27;, &#x27;1443&#x27;, &#x27;1444&#x27;, &#x27;1445&#x27;, &#x27;1446&#x27;, &#x27;1447&#x27;, &#x27;1448&#x27;, &#x27;1449&#x27;, &#x27;1450&#x27;, &#x27;1451&#x27;, &#x27;1452&#x27;, &#x27;1453&#x27;, &#x27;1454&#x27;, &#x27;1455&#x27;, &#x27;1456&#x27;, &#x27;1457&#x27;, &#x27;1458&#x27;, &#x27;1459&#x27;, &#x27;1460&#x27;, &#x27;1461&#x27;, &#x27;1462&#x27;, &#x27;1463&#x27;, &#x27;1464&#x27;, &#x27;1465&#x27;, &#x27;1466&#x27;, &#x27;1467&#x27;, &#x27;1468&#x27;, &#x27;1469&#x27;, &#x27;1470&#x27;, &#x27;1471&#x27;, &#x27;1472&#x27;, &#x27;1473&#x27;, &#x27;1474&#x27;, &#x27;1475&#x27;, &#x27;1476&#x27;, &#x27;1477&#x27;, &#x27;1478&#x27;, &#x27;1479&#x27;, &#x27;1480&#x27;, &#x27;1481&#x27;, &#x27;1482&#x27;, &#x27;1483&#x27;, &#x27;1484&#x27;, &#x27;1485&#x27;, &#x27;1486&#x27;, &#x27;1487&#x27;, &#x27;1488&#x27;, &#x27;1489&#x27;, &#x27;1490&#x27;, &#x27;1491&#x27;, &#x27;1492&#x27;, &#x27;1493&#x27;, &#x27;1494&#x27;, &#x27;1495&#x27;, &#x27;1496&#x27;, &#x27;1497&#x27;, &#x27;1498&#x27;, &#x27;1499&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(bootstrap=True, class_weight=&#x27;balanced&#x27;, max_depth=6,\n",
       "                     min_samples_leaf=2, n_estimators=400, n_jobs=-1,\n",
       "                     random_state=75, verbose=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGBoost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eta=0.05, eval_metric=&#x27;mae&#x27;,\n",
       "              feature_types=None, gamma=0.01, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=0.1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>CatBoost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7fecba05c5e0&gt;</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(verbose=False)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('ExtraTrees',\n",
       "                                Pipeline(steps=[('columntransformer',\n",
       "                                                 ColumnTransformer(transformers=[('numerical',\n",
       "                                                                                  Pipeline(steps=[('imputer',\n",
       "                                                                                                   SimpleImputer()),\n",
       "                                                                                                  ('scaler',\n",
       "                                                                                                   StandardScaler())]),\n",
       "                                                                                  ['0',\n",
       "                                                                                   '1',\n",
       "                                                                                   '2',\n",
       "                                                                                   '3',\n",
       "                                                                                   '4',\n",
       "                                                                                   '5',\n",
       "                                                                                   '6',\n",
       "                                                                                   '7',\n",
       "                                                                                   '8',\n",
       "                                                                                   '9',\n",
       "                                                                                   '10',\n",
       "                                                                                   '11',\n",
       "                                                                                   '12',\n",
       "                                                                                   '13',\n",
       "                                                                                   '14',\n",
       "                                                                                   '15',\n",
       "                                                                                   '16',\n",
       "                                                                                   '17',\n",
       "                                                                                   '18',\n",
       "                                                                                   '19',\n",
       "                                                                                   '20',\n",
       "                                                                                   '21',\n",
       "                                                                                   '22',\n",
       "                                                                                   '23',\n",
       "                                                                                   '24',\n",
       "                                                                                   '25',\n",
       "                                                                                   '26',\n",
       "                                                                                   '27',\n",
       "                                                                                   '28',\n",
       "                                                                                   '29', ...]),\n",
       "                                                                                 ('...\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None, max_depth=6,\n",
       "                                              max_leaves=None,\n",
       "                                              min_child_weight=0.1, missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              multi_strategy=None,\n",
       "                                              n_estimators=200, n_jobs=None,\n",
       "                                              num_parallel_tree=None, ...)),\n",
       "                               ('CatBoost',\n",
       "                                <catboost.core.CatBoostClassifier object at 0x7fecba05c5e0>)],\n",
       "                   final_estimator=LogisticRegression(verbose=False), n_jobs=-1,\n",
       "                   verbose=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4290515",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/data_real_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d3cf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = pd.DataFrame(stacking_classifier.predict(test), columns=['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3547745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01100001000000000010000000010100000001100011000000'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([str(i) for i in list(stacking_classifier.predict(test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fd53648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict['class'].value_counts()[1] / test_predict['class'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0aecb263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01000000001000000100000001010000100001000000010001'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hallteon/.local/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [00:03:11] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "'01000000001000000100000001010000100001000000010001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d145dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
